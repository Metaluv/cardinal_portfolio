import { ArticleLayout } from '@/components/ArticleLayout'

export const meta = {
  author: 'Jason Cardinal',
  date: '2025-01-02',
  title: 'Python for Data Science and Engineering Applications',
  description:
    'Harness the power of NumPy, Pandas, and scientific computing libraries for engineering analysis and data-driven decision making.',
}

export default (props) => <ArticleLayout meta={meta} {...props} />

## The Power of Python in Engineering

Python has revolutionized engineering workflows by providing powerful tools for numerical computation, data analysis, and visualization. Through my work in agricultural innovation and engineering studies, I've discovered that mastering these tools transforms how we approach complex problems.

## NumPy: The Foundation of Scientific Computing

NumPy provides the numerical backbone for scientific Python. Its n-dimensional arrays are faster and more memory-efficient than Python lists.

### Array Fundamentals

```python
import numpy as np

# Creating arrays
temperatures = np.array([22.5, 23.1, 21.8, 24.2, 22.9])
rainfall = np.linspace(0, 100, 12)  # 12 months
soil_grid = np.zeros((10, 10))  # 10x10 field grid

# Array operations (vectorized - no loops needed!)
celsius = np.array([20, 25, 30, 18, 22])
fahrenheit = celsius * 9/5 + 32

# Statistical operations
mean_temp = temperatures.mean()
std_dev = temperatures.std()
max_temp = temperatures.max()

# Boolean indexing
hot_days = temperatures[temperatures > 23]
frost_risk = temperatures < 5

# Multi-dimensional arrays for field mapping
field_moisture = np.random.uniform(20, 80, size=(50, 100))
dry_areas = np.where(field_moisture < 30)
print(f"Dry areas at coordinates: {list(zip(dry_areas[0], dry_areas[1]))}")
```

### Engineering Calculations with NumPy

```python
# Irrigation flow rate calculations
pipe_diameters = np.array([2, 3, 4, 5, 6])  # inches
velocity = 5  # ft/s
flow_rates = np.pi * (pipe_diameters/2)**2 * velocity

# Matrix operations for structural analysis
stiffness_matrix = np.array([
    [1000, -500, 0],
    [-500, 1500, -1000],
    [0, -1000, 1000]
])
forces = np.array([100, 0, -50])
displacements = np.linalg.solve(stiffness_matrix, forces)

# Signal processing for sensor data
time = np.linspace(0, 1, 1000)
sensor_signal = np.sin(2 * np.pi * 5 * time) + 0.5 * np.random.randn(1000)
fft_result = np.fft.fft(sensor_signal)
frequencies = np.fft.fftfreq(len(sensor_signal))
```

## Pandas: Data Analysis Powerhouse

Pandas excels at handling structured data, making it perfect for analyzing agricultural and engineering datasets.

### DataFrame Essentials

```python
import pandas as pd
from datetime import datetime, timedelta

# Creating DataFrames
crop_data = pd.DataFrame({
    'crop': ['Corn', 'Wheat', 'Soybeans', 'Canola'],
    'yield_per_acre': [180, 50, 45, 40],
    'price_per_bushel': [5.50, 7.25, 12.80, 15.00],
    'water_needs': ['High', 'Medium', 'Medium', 'Low']
})

# Reading real data
weather_data = pd.read_csv('weather_history.csv', parse_dates=['date'])
sensor_readings = pd.read_excel('greenhouse_sensors.xlsx', sheet_name='July')

# Data manipulation
crop_data['revenue_per_acre'] = crop_data['yield_per_acre'] * crop_data['price_per_bushel']
crop_data['profit_margin'] = crop_data['revenue_per_acre'] - 500  # $500 cost assumption

# Filtering and sorting
high_yield_crops = crop_data[crop_data['yield_per_acre'] > 50]
sorted_by_profit = crop_data.sort_values('profit_margin', ascending=False)

# Grouping and aggregation
monthly_summary = weather_data.groupby(weather_data['date'].dt.month).agg({
    'temperature': ['mean', 'max', 'min'],
    'rainfall': 'sum',
    'humidity': 'mean'
})
```

### Time Series Analysis

```python
# Generate time series data
dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')
growth_data = pd.DataFrame({
    'date': dates,
    'height_cm': 5 + np.cumsum(np.random.normal(0.2, 0.1, len(dates))),
    'water_ml': np.random.uniform(200, 500, len(dates)),
    'temperature': 20 + 10*np.sin(np.arange(len(dates))*2*np.pi/365) + np.random.normal(0, 2, len(dates))
})

# Set date as index
growth_data.set_index('date', inplace=True)

# Resampling
weekly_avg = growth_data.resample('W').mean()
monthly_total_water = growth_data['water_ml'].resample('M').sum()

# Rolling statistics (moving averages)
growth_data['height_7day_avg'] = growth_data['height_cm'].rolling(window=7).mean()
growth_data['temp_30day_avg'] = growth_data['temperature'].rolling(window=30).mean()

# Seasonal decomposition
from statsmodels.tsa.seasonal import seasonal_decompose
decomposition = seasonal_decompose(growth_data['temperature'], model='additive', period=365)
```

## Matplotlib: Visualization for Insights

Effective visualization transforms data into understanding.

```python
import matplotlib.pyplot as plt

# Set style for better-looking plots
plt.style.use('seaborn-v0_8-darkgrid')

# Multi-panel figure for comprehensive analysis
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Subplot 1: Crop yield comparison
axes[0, 0].bar(crop_data['crop'], crop_data['yield_per_acre'], color=['green', 'gold', 'brown', 'yellow'])
axes[0, 0].set_title('Crop Yields per Acre')
axes[0, 0].set_ylabel('Bushels per Acre')
axes[0, 0].set_xlabel('Crop Type')

# Subplot 2: Time series with multiple y-axes
ax1 = axes[0, 1]
ax2 = ax1.twinx()
ax1.plot(growth_data.index, growth_data['height_cm'], 'g-', label='Height')
ax2.plot(growth_data.index, growth_data['temperature'], 'r-', alpha=0.7, label='Temperature')
ax1.set_xlabel('Date')
ax1.set_ylabel('Height (cm)', color='g')
ax2.set_ylabel('Temperature (Â°C)', color='r')
ax1.set_title('Plant Growth vs Temperature')

# Subplot 3: Scatter plot with regression
axes[1, 0].scatter(growth_data['water_ml'], growth_data['height_cm'], alpha=0.5)
z = np.polyfit(growth_data['water_ml'], growth_data['height_cm'], 1)
p = np.poly1d(z)
axes[1, 0].plot(growth_data['water_ml'], p(growth_data['water_ml']), "r--", alpha=0.8)
axes[1, 0].set_xlabel('Water (ml)')
axes[1, 0].set_ylabel('Height (cm)')
axes[1, 0].set_title('Water vs Growth Correlation')

# Subplot 4: Heatmap of field moisture
im = axes[1, 1].imshow(field_moisture, cmap='RdYlBu', aspect='auto')
axes[1, 1].set_title('Field Moisture Map')
axes[1, 1].set_xlabel('Field Width (m)')
axes[1, 1].set_ylabel('Field Length (m)')
plt.colorbar(im, ax=axes[1, 1], label='Moisture (%)')

plt.tight_layout()
plt.show()
```

## SciPy: Advanced Scientific Computing

SciPy builds on NumPy for specialized scientific computations.

```python
from scipy import optimize, integrate, interpolate, signal

# Optimization: Finding optimal irrigation schedule
def water_cost_function(water_amounts):
    """Minimize water use while maintaining growth."""
    growth = np.sum(np.log(water_amounts + 1))  # Diminishing returns
    cost = np.sum(water_amounts) * 0.01  # Water cost
    return cost - growth

constraints = {'type': 'ineq', 'fun': lambda x: x.sum() - 100}  # Min 100L total
bounds = [(10, 100) for _ in range(7)]  # Daily limits
result = optimize.minimize(water_cost_function, x0=[50]*7, bounds=bounds, constraints=constraints)

# Interpolation: Filling sensor data gaps
time_points = np.array([0, 2, 5, 8, 12, 18, 24])
temp_readings = np.array([15, 18, 22, 25, 24, 20, 16])
f_cubic = interpolate.interp1d(time_points, temp_readings, kind='cubic')
time_continuous = np.linspace(0, 24, 100)
temp_interpolated = f_cubic(time_continuous)

# Signal processing: Filtering noisy sensor data
fs = 100  # Sampling frequency
cutoff = 5  # Cutoff frequency
nyquist = fs / 2
normal_cutoff = cutoff / nyquist
b, a = signal.butter(4, normal_cutoff, btype='low')
filtered_signal = signal.filtfilt(b, a, sensor_signal)

# Integration: Calculating area under curve (e.g., daily light integral)
light_intensity = lambda t: 500 * np.sin(np.pi * t / 12) if 6 <= t <= 18 else 0
daily_light_integral, error = integrate.quad(light_intensity, 0, 24)
```

## Real-World Project: Agricultural Analytics Dashboard

Combining all tools for a complete solution:

```python
class AgriculturalAnalytics:
    """Complete analytics system for farm management."""
    
    def __init__(self, data_path):
        self.weather_data = pd.read_csv(f"{data_path}/weather.csv", parse_dates=['date'])
        self.crop_data = pd.read_csv(f"{data_path}/crops.csv")
        self.sensor_data = pd.read_csv(f"{data_path}/sensors.csv", parse_dates=['timestamp'])
        
    def analyze_growing_conditions(self):
        """Analyze if conditions are suitable for planting."""
        recent_weather = self.weather_data.tail(7)
        
        avg_temp = recent_weather['temperature'].mean()
        total_rainfall = recent_weather['rainfall'].sum()
        frost_risk = (recent_weather['min_temp'] < 0).any()
        
        suitable = avg_temp > 10 and total_rainfall < 50 and not frost_risk
        
        return {
            'suitable': suitable,
            'avg_temperature': avg_temp,
            'total_rainfall': total_rainfall,
            'frost_risk': frost_risk
        }
    
    def predict_yield(self, crop_type):
        """Predict yield based on historical data."""
        crop_history = self.crop_data[self.crop_data['type'] == crop_type]
        
        # Simple linear regression
        X = crop_history[['rainfall', 'temperature', 'fertilizer']].values
        y = crop_history['yield'].values
        
        from sklearn.linear_model import LinearRegression
        model = LinearRegression()
        model.fit(X, y)
        
        # Current conditions
        current_conditions = np.array([[
            self.weather_data['rainfall'].tail(30).sum(),
            self.weather_data['temperature'].tail(30).mean(),
            100  # Planned fertilizer
        ]])
        
        predicted_yield = model.predict(current_conditions)[0]
        return predicted_yield
    
    def optimize_irrigation(self):
        """Determine optimal irrigation schedule."""
        soil_moisture = self.sensor_data['soil_moisture'].tail(24).values
        
        # Calculate water deficit
        optimal_moisture = 60  # percentage
        deficit = optimal_moisture - soil_moisture
        deficit[deficit < 0] = 0  # No negative values
        
        # Distribute water based on deficit
        total_water_available = 1000  # liters
        water_distribution = (deficit / deficit.sum()) * total_water_available
        
        return pd.DataFrame({
            'hour': range(24),
            'moisture': soil_moisture,
            'water_needed': water_distribution
        })
    
    def generate_report(self):
        """Generate comprehensive farm report."""
        conditions = self.analyze_growing_conditions()
        corn_yield = self.predict_yield('corn')
        irrigation = self.optimize_irrigation()
        
        # Create visualizations
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Weather trends
        self.weather_data.tail(30).plot(x='date', y=['temperature', 'rainfall'], 
                                        ax=axes[0, 0], secondary_y=['rainfall'])
        axes[0, 0].set_title('30-Day Weather Trends')
        
        # Yield predictions
        crops = ['corn', 'wheat', 'soybeans']
        yields = [self.predict_yield(c) for c in crops]
        axes[0, 1].bar(crops, yields)
        axes[0, 1].set_title('Predicted Yields')
        
        # Irrigation schedule
        irrigation.plot(x='hour', y=['moisture', 'water_needed'], ax=axes[1, 0])
        axes[1, 0].set_title('24-Hour Irrigation Plan')
        
        # Sensor statistics
        sensor_stats = self.sensor_data.describe()
        axes[1, 1].axis('tight')
        axes[1, 1].axis('off')
        table_data = sensor_stats.round(2).values
        axes[1, 1].table(cellText=table_data, 
                        colLabels=sensor_stats.columns,
                        rowLabels=sensor_stats.index,
                        cellLoc='center',
                        loc='center')
        axes[1, 1].set_title('Sensor Statistics')
        
        plt.tight_layout()
        plt.savefig('farm_report.png', dpi=300, bbox_inches='tight')
        
        return {
            'conditions': conditions,
            'predicted_yields': dict(zip(crops, yields)),
            'irrigation_plan': irrigation
        }
```

## Best Practices for Scientific Python

1. **Vectorize operations**: Use NumPy operations instead of loops
2. **Profile your code**: Identify bottlenecks with `%timeit`
3. **Use appropriate data structures**: DataFrames for tables, arrays for numerical
4. **Handle missing data**: Use `pd.fillna()` or `np.nan` appropriately
5. **Document units**: Always specify units in variable names or comments
6. **Validate results**: Sanity check against known values
7. **Version control data**: Track data sources and transformations

## Your Path Forward

Start with real data from your domain. Whether it's sensor readings, financial records, or experimental results, apply these tools to solve actual problems. The combination of NumPy's computational power, Pandas' data manipulation, and Matplotlib's visualization creates a formidable toolkit for any engineer or data scientist.

Remember: The goal isn't to memorize every functionâit's to understand the capabilities and know where to look when you need them. Build your own library of useful code snippets, and soon you'll be solving complex engineering problems with elegant Python solutions.